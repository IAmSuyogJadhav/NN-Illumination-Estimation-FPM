{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fpm import *\n",
    "# from params import *\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import scipy.io as io\n",
    "# import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from fvcore.common.file_io import PathManager\n",
    "from fvcore.common.checkpoint import Checkpointer\n",
    "import comm\n",
    "import c2_model_loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionCheckpointer(Checkpointer):\n",
    "    \"\"\"\n",
    "    Same as :class:`Checkpointer`, but is able to handle models in detectron & detectron2\n",
    "    model zoo, and apply conversions for legacy models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, save_dir=\"\", *, save_to_disk=None, **checkpointables):\n",
    "        is_main_process = comm.is_main_process()\n",
    "        super().__init__(\n",
    "            model,\n",
    "            save_dir,\n",
    "            save_to_disk=is_main_process if save_to_disk is None else save_to_disk,\n",
    "            **checkpointables,\n",
    "        )\n",
    "\n",
    "    def _load_file(self, filename):\n",
    "        if filename.endswith(\".pkl\"):\n",
    "            with PathManager.open(filename, \"rb\") as f:\n",
    "                data = pickle.load(f, encoding=\"latin1\")\n",
    "            if \"model\" in data and \"__author__\" in data:\n",
    "                # file is in Detectron2 model zoo format\n",
    "                self.logger.info(\"Reading a file from '{}'\".format(data[\"__author__\"]))\n",
    "                return data\n",
    "            else:\n",
    "                # assume file is from Caffe2 / Detectron1 model zoo\n",
    "                if \"blobs\" in data:\n",
    "                    # Detection models have \"blobs\", but ImageNet models don't\n",
    "                    data = data[\"blobs\"]\n",
    "                data = {k: v for k, v in data.items() if not k.endswith(\"_momentum\")}\n",
    "                return {\"model\": data, \"__author__\": \"Caffe2\", \"matching_heuristics\": True}\n",
    "\n",
    "        loaded = super()._load_file(filename)  # load native pth checkpoint\n",
    "        if \"model\" not in loaded:\n",
    "            loaded = {\"model\": loaded}\n",
    "        return loaded\n",
    "\n",
    "    def _load_model(self, checkpoint):\n",
    "        if checkpoint.get(\"matching_heuristics\", False):\n",
    "            self._convert_ndarray_to_tensor(checkpoint[\"model\"])\n",
    "            # convert weights by name-matching heuristics\n",
    "            model_state_dict = self.model.state_dict()\n",
    "            c2_model_loading.align_and_update_state_dicts(\n",
    "                model_state_dict,\n",
    "                checkpoint[\"model\"],\n",
    "                c2_conversion=checkpoint.get(\"__author__\", None) == \"Caffe2\",\n",
    "            )\n",
    "            checkpoint[\"model\"] = model_state_dict\n",
    "        # for non-caffe2 models, use standard ways to load it\n",
    "        incompatible = super()._load_model(checkpoint)\n",
    "        if incompatible is None:  # support older versions of fvcore\n",
    "            return None\n",
    "\n",
    "        model_buffers = dict(self.model.named_buffers(recurse=False))\n",
    "        for k in [\"pixel_mean\", \"pixel_std\"]:\n",
    "            # Ignore missing key message about pixel_mean/std.\n",
    "            # Though they may be missing in old checkpoints, they will be correctly\n",
    "            # initialized from config anyway.\n",
    "            if k in model_buffers:\n",
    "                try:\n",
    "                    incompatible.missing_keys.remove(k)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        return incompatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fvcore.common.registry import Registry\n",
    "import transform as T\n",
    "\n",
    "META_ARCH_REGISTRY = Registry(\"META_ARCH\")  # noqa F401 isort:skip\n",
    "META_ARCH_REGISTRY.__doc__ = \"\"\"\n",
    "Registry for meta-architectures, i.e. the whole model.\n",
    "The registered object will be called with `obj(cfg)`\n",
    "and expected to return a `nn.Module` object.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def build_model(cfg):\n",
    "    \"\"\"\n",
    "    Build the whole model architecture, defined by ``cfg.MODEL.META_ARCHITECTURE``.\n",
    "    Note that it does not load any weights from ``cfg``.\n",
    "    \"\"\"\n",
    "    meta_arch = cfg.MODEL.META_ARCHITECTURE\n",
    "    model = META_ARCH_REGISTRY.get(meta_arch)(cfg)\n",
    "    model.to(torch.device(cfg.MODEL.DEVICE))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefaultPredictor:\n",
    "    \"\"\"\n",
    "    Create a simple end-to-end predictor with the given config that runs on\n",
    "    single device for a single input image.\n",
    "    Compared to using the model directly, this class does the following additions:\n",
    "    1. Load checkpoint from `cfg.MODEL.WEIGHTS`.\n",
    "    2. Always take BGR image as the input and apply conversion defined by `cfg.INPUT.FORMAT`.\n",
    "    3. Apply resizing defined by `cfg.INPUT.{MIN,MAX}_SIZE_TEST`.\n",
    "    4. Take one input image and produce a single output, instead of a batch.\n",
    "    If you'd like to do anything more fancy, please refer to its source code\n",
    "    as examples to build and use the model manually.\n",
    "    Attributes:\n",
    "        metadata (Metadata): the metadata of the underlying dataset, obtained from\n",
    "            cfg.DATASETS.TEST.\n",
    "    Examples:\n",
    "    ::\n",
    "        pred = DefaultPredictor(cfg)\n",
    "        inputs = cv2.imread(\"input.jpg\")\n",
    "        outputs = pred(inputs)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        self.cfg = cfg.clone()  # cfg can be modified by model\n",
    "        self.model = build_model(self.cfg)\n",
    "        self.model.eval()\n",
    "#         if len(cfg.DATASETS.TEST):\n",
    "#             self.metadata = MetadataCatalog.get(cfg.DATASETS.TEST[0])\n",
    "\n",
    "        checkpointer = DetectionCheckpointer(self.model)\n",
    "        checkpointer.load(cfg.MODEL.WEIGHTS)\n",
    "        \n",
    "        self.aug = T.ResizeShortestEdge(\n",
    "            [cfg.INPUT.MIN_SIZE_TEST, cfg.INPUT.MIN_SIZE_TEST], cfg.INPUT.MAX_SIZE_TEST\n",
    "        )\n",
    "\n",
    "        self.input_format = cfg.INPUT.FORMAT\n",
    "        assert self.input_format in [\"RGB\", \"BGR\"], self.input_format\n",
    "    \n",
    "    \n",
    "    def __call__(self, original_image):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            original_image (np.ndarray): an image of shape (H, W, C) (in BGR order).\n",
    "        Returns:\n",
    "            predictions (dict):\n",
    "                the output of the model for one image only.\n",
    "                See :doc:`/tutorials/models` for details about the format.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():  # https://github.com/sphinx-doc/sphinx/issues/4258\n",
    "            # Apply pre-processing to image.\n",
    "            if self.input_format == \"RGB\":\n",
    "                # whether the model expects BGR inputs or RGB\n",
    "                original_image = original_image[:, :, ::-1]\n",
    "            height, width = original_image.shape[:2]\n",
    "            image = self.aug.get_transform(original_image).apply_image(original_image)\n",
    "            image = torch.as_tensor(image.astype(\"float32\").transpose(2, 0, 1))\n",
    "\n",
    "            inputs = {\"image\": image, \"height\": height, \"width\": width}\n",
    "            predictions = self.model([inputs])[0]\n",
    "            return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_tiff(img_path, uint8=True, cm=None):\n",
    "    \"\"\"\n",
    "    read_tiff(img_path, uint8=True, cm=None)\n",
    "        Reads a multi-page tiff file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    `img_path`: String, required\n",
    "            Path to the tiff file.\n",
    "    `uint8`: Boolean, optional\n",
    "            Specify whether to downscale the image to uint8 or not. Defaults to True.\n",
    "    `cm`: Integer (range: [1, 12]), optional\n",
    "            Defaults to None. If specified, the corresponding colormap is applied\n",
    "            and returned along with the raw images.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    `imgs`: A list of images read from the tiff file.\n",
    "    (conditional) `imgs_cm`: The colormap-applied images in a list. Returned only if `cm` is specified.\n",
    "    \"\"\"\n",
    "    # Read the image\n",
    "    read, imgs = cv2.imreadmulti(img_path, flags=cv2.IMREAD_ANYDEPTH) \n",
    "    assert read, \"The image could not be read. Make sure the file is accessible and try again.\"\n",
    "    \n",
    "    if uint8:\n",
    "        # Scale down to uint8\n",
    "        imgs = [cv2.convertScaleAbs(img, alpha=(255/img.max())) for img in imgs] \n",
    "    if cm is not None: \n",
    "        # Apply colormap (for visualization only)\n",
    "        imgs_cm = [cv2.applyColorMap(img, cm) for img in imgs] \n",
    "        return imgs, imgs_cm\n",
    "\n",
    "    return imgs\n",
    "\n",
    "\n",
    "def preprocess(imgs, visualize=False, return_rgb=False, preprocess_fft=True, resize=None):\n",
    "    \"\"\"\n",
    "    preprocess(imgs, visualize=false, return_rgb=False)\n",
    "        Preprocess a list of images for training using the following pipeline. \n",
    "        Image > Magnitude Spectrum > NL Means Denoising > Bilateral Filter > Morph. Closing > Sharpening \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    `imgs`: list or a Numpy array, required\n",
    "            A single image or a list of images to be preprocessed.\n",
    "    `visualize`: Boolean, optional\n",
    "            Defaults to False. If set to True, visualizes the last processed image.\n",
    "            For debugging/testing\n",
    "    `return_rgb`: Boolean, optional\n",
    "            Defaults to False. If set to True, triplicates the grayscale image into 3 channels. Required \n",
    "            while evaluating the model.\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    `out`: List of preprocessed images, in the order they were provided.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not isinstance(imgs, list):  # A single image is provided\n",
    "        imgs = [imgs,]  # To reduce redundant code later in the function\n",
    "        \n",
    "    # Calculate FFT\n",
    "    fs = [20*np.log(1 + np.abs(np.fft.fft2(img))) for img in imgs]  # magnitude spectrum\n",
    "    fshifts = [np.fft.fftshift(f) for f in fs]  # Shift zero frquency component\n",
    "    fshifts = [cv2.convertScaleAbs(fshift, alpha =255/fshift.max()) for fshift in fshifts] # Convert to uint8\n",
    "\n",
    "    # Pre-processing FFT images\n",
    "    if preprocess_fft:  # See if it is asked for\n",
    "        kernel_sharpening = np.array(\n",
    "                [[0,-1,0],\n",
    "                [-1,+5,-1],  # The sharpen kernel, required for sharpening\n",
    "                [0,-1,0]]\n",
    "        )\n",
    "\n",
    "        out = []\n",
    "        for fshift in fshifts:\n",
    "            fshift1 = cv2.fastNlMeansDenoising(fshift, 9, 9, 7, 21)  # Denoising\n",
    "            fshift2 = cv2.bilateralFilter(fshift1, 5, 75, 75)  # Bilateral Filter (Blurring)\n",
    "            fshift2 = cv2.morphologyEx(fshift2, cv2.MORPH_CLOSE, np.ones((3, 3)))  # Closing\n",
    "            fshift2 = cv2.filter2D(fshift2, -1, kernel_sharpening)  # Sharpening\n",
    "            out.append(fshift2)  # Store the result\n",
    "        \n",
    "        # Visualize the results\n",
    "        if visualize:\n",
    "            plt.figure(figsize=(15, 45))\n",
    "            plt.subplot(131)\n",
    "            plt.title('Input')\n",
    "            plt.imshow(fshift)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.subplot(132)\n",
    "            plt.title('NL Means Denoising')\n",
    "            plt.imshow(fshift1)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.subplot(133)\n",
    "            plt.title('Bilateral Filter + Closing + Sharpening')\n",
    "            plt.imshow(fshift2)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:  # Return without preprocessing\n",
    "        out = fshifts  \n",
    "\n",
    "    if resize is not None:\n",
    "        out = [cv2.resize(img, (resize, resize)) for img in out]\n",
    "    \n",
    "    if return_rgb:\n",
    "        out = [np.dstack([im, im, im]) for im in out]  # Stack along 2nd axis to get (imagesize, imagesize, 3) shape\n",
    "\n",
    "    return out\n",
    "\n",
    "def angle_between(p1, p2):\n",
    "    ang1 = np.arctan2(*p1[::-1])\n",
    "    ang2 = np.arctan2(*p2[::-1])\n",
    "    return np.rad2deg((ang1 - ang2) % (2 * np.pi))\n",
    "\n",
    "\n",
    "def _get_r(discs, orig):\n",
    "    rs = []\n",
    "    for disc in discs:\n",
    "        if disc==0:\n",
    "            rs.append(0)\n",
    "        else:\n",
    "            x, y = disc[0]\n",
    "            x, y = abs(x - orig), abs(y - orig)\n",
    "            rs.append(np.sqrt(x**2 + y**2))\n",
    "    return rs\n",
    "            \n",
    "\n",
    "\n",
    "def _get_discs(preds, imagesize, idxs=None, total=None, calibrate=False, calibrate_v2=False, tol=None, fill_empty=False, return_discs_raw=False):\n",
    "    \"\"\"\n",
    "    _get_discs(preds, imagesize)\n",
    "        Used internally by Predictor class. Automatically identifies the disc to be returned.\n",
    "        Assumes the frames start from theta = 0 degrees (origin at the center of the image).\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    `preds`: List, required\n",
    "            The list of predictions returned by the model.\n",
    "    `imagesize`: Integer, required\n",
    "            Length of one side of the image. The image is assumed to have\n",
    "            same length and width.\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    `discs_final`: List of shortlisted discs' center coordinates (x, y). If no discs were found in a frame,\n",
    "            0 is put at that index.\n",
    "    `radii`: List of radii of shortlisted discs. If no discs were found in a frame, 0 is put at that index.\n",
    "    \"\"\"\n",
    "    discs = []\n",
    "    radii = []\n",
    "    \n",
    "    orig = imagesize // 2 - 1  # Origin\n",
    "    for i, pred in enumerate(preds):\n",
    "        if len(pred) == 0:  # Avoid empty predictions\n",
    "            discs.append(0)\n",
    "            radii.append(0)\n",
    "            continue\n",
    "            \n",
    "        # Get center of the disc\n",
    "        x1 = pred[:, 0]  # Top Left Corner X\n",
    "        y1 = pred[:, 1]  # Top Left Corner Y\n",
    "        x2 = pred[:, 2]  # Bottom Right Corner X\n",
    "        y2 = pred[:, 3]  # Bottom Right Corner Y\n",
    "\n",
    "        x = np.abs((x1 + x2) / 2 - orig).mean()\n",
    "        y = np.abs((y1 + y2) / 2 - orig).mean()\n",
    "\n",
    "        # Get both the discs' coordinates\n",
    "        sign_x = (np.sign((x1 + x2) / 2 - orig)).astype(int)[0]\n",
    "        sign_y = (np.sign((y1 + y2) / 2 - orig)).astype(int)[0]\n",
    "        discs.append([\n",
    "            [orig + sign_x * x, orig + sign_y * y],  # One of the discs\n",
    "            [orig - sign_x * x, orig - sign_y * y]   # The disc opposite to it\n",
    "        ])\n",
    "        \n",
    "        # Get radius of the disc\n",
    "        radii.append((np.abs((y1 - y2) / 2).mean() + np.abs((x1 - x2) / 2).mean()) / 2)\n",
    "        \n",
    "    # Divide plane (360) into `frames` no. of divisions\n",
    "    frames = len(preds) if total is None else total\n",
    "    \n",
    "#     r = np.mean(radii) # imagesize // 2 - 1  # Length of the vector\n",
    "#     rs = _get_r(discs, orig)\n",
    "    \n",
    "#     thetas = list(range(90, 360, 360 // frames)) + list(range(0, 90, 360 // frames))  # 0:(360 // frames):360\n",
    "#     thetas = list(np.mod(np.arange(90 ,  450, 360/frames), 360))\n",
    "    thetas = list(np.arange(0 ,  360, 360/frames))\n",
    "#     thetas = [np.deg2rad(t) for t in thetas] # DEBUG 28-05\n",
    "\n",
    "#     x = lambda r, t: int(orig + r * np.cos(np.deg2rad(t)))\n",
    "#     y = lambda r, t: int(orig + r * np.sin(np.deg2rad(t)))\n",
    "\n",
    "#     points = [(x(r, theta), y(r, theta)) for r, theta in zip(rs, thetas)]\n",
    "    ref = [1, 0]\n",
    "    \n",
    "    # Empty frames\n",
    "    empty_frames = [True if disc==0 else False for disc in discs]\n",
    "    \n",
    "    # Choose the required disc out of the two discs\n",
    "    discs_final = []\n",
    "    if idxs is None:\n",
    "        idxs = list(range(len(discs)))\n",
    "    if tol is None or tol.lower() == 'none':\n",
    "        tol = 360\n",
    "    elif tol == 'auto':\n",
    "        tol = 2 * 360/frames\n",
    "\n",
    "    # Keep track of offsets\n",
    "    offsets = []\n",
    "    \n",
    "    for idx, disc in zip(idxs, discs):\n",
    "        if disc == 0:  # Avoid empty predictions\n",
    "            discs_final.append(0)\n",
    "            offsets.append([0, 0, 0, 0])\n",
    "            continue\n",
    "\n",
    "#         d0 = euclid(points[idx], disc[0])\n",
    "#         d1 = euclid(points[idx], disc[1]) \n",
    "\n",
    "#         d0 = [disc[0][0] - orig, -(disc[0][1] - orig)]  # DEBUG 28-05\n",
    "#         d0 = dot(d0, ref) / (dot(d0, d0) * dot(ref, ref))  # DEBUG 28-05\n",
    "#         if np.sign(d0) == -1:  # DEBUG 28-05\n",
    "#             d0 = 2*np.pi + d0  # DEBUG 28-05\n",
    "#         d0 = np.mod(d0, 2*np.pi)  # DEBUG 28-05\n",
    "\n",
    "        d0 = [disc[0][0] - orig, orig - disc[0][1]]  # DEBUG 28-05\n",
    "        d0 = angle_between(ref, d0)  # DEBUG 28-05\n",
    "        \n",
    "        if disc == discs[-1]:  # Last disc might overshoot reference line\n",
    "            off_d0_ = thetas[idx] - (360-d0)  # Offset without changing the sign\n",
    "            d0_ = abs(thetas[idx] - (360-d0))\n",
    "        \n",
    "        off_d0 = thetas[idx] - d0\n",
    "        d0 = abs(thetas[idx] - d0)\n",
    "        \n",
    "#         d1 = [disc[1][0] - orig, -(disc[1][1] - orig)]\n",
    "#         d1 = dot(d1, ref) / (dot(d1, d1) * dot(ref, ref))\n",
    "#         if np.sign(d1) == -1:\n",
    "#             d1 = 2*np.pi + d1\n",
    "#         d1 = np.mod(d1, 2*np.pi)\n",
    "        d1 = [disc[1][0] - orig, orig - disc[1][1]]  # DEBUG 28-05\n",
    "        d1 = angle_between(ref, d1)  # DEBUG 28-05\n",
    "        if disc == discs[-1]:  # Last disc might overshoot reference line\n",
    "            off_d1_ = thetas[idx] - (360-d1)\n",
    "            d1_ = abs(thetas[idx] - (360-d1))\n",
    "        off_d1 = thetas[idx] - d1\n",
    "        d1 = abs(thetas[idx] - d1)\n",
    "        \n",
    "#         print(d0, d1)  #DEBUG\n",
    "        if (d0 > tol) and (d1 > tol):\n",
    "            discs_final.append(0)\n",
    "            offsets.append([0, 0, 0, 0])\n",
    "            continue\n",
    "\n",
    "        if disc == discs[-1]:  # Last disc might overshoot reference line\n",
    "            m = min(d0, d0_, d1, d1_)\n",
    "            discs_final.append(disc[0] if (d0 == m) or (d0_ == m) else disc[1])\n",
    "\n",
    "#             if m == d0:\n",
    "#                 offsets.append(off_d0)\n",
    "#             elif m == d0_:\n",
    "#                 offsets.append(off_d0_)\n",
    "#             elif m == d1:\n",
    "#                 offsets.append(off_d1)\n",
    "#             elif m == d1_:\n",
    "#                 offsets.append(off_d1_)\n",
    "            \n",
    "            offsets.append([off_d0, off_d0_, off_d1, off_d1_])\n",
    "            continue\n",
    "\n",
    "        # Save correct offset (with sign)\n",
    "        discs_final.append(disc[0] if d0 < d1 else disc[1])\n",
    "        \n",
    "        m = min(d0, d1)\n",
    "        # Save correct offset (with sign)\n",
    "#         if m == d0:\n",
    "#                 offsets.append(off_d0)    \n",
    "#         elif m == d1:\n",
    "#                 offsets.append(off_d1)\n",
    "        offsets.append([off_d0, np.inf, off_d1, np.inf])\n",
    "\n",
    "#     print(tol, offsets)\n",
    "    if calibrate:\n",
    "        discs_final, radii = _calibrate(discs_final, radii, orig, idxs, total, fill_empty=fill_empty)\n",
    "    elif calibrate_v2:\n",
    "        discs_final, radii = _calibrate_v2(discs_final, radii, empty_frames, orig, idxs, total, fill_empty=fill_empty)\n",
    "        \n",
    "    if not return_discs_raw:\n",
    "        return discs_final, radii\n",
    "    else:\n",
    "        return discs_final, radii, discs\n",
    "\n",
    "\n",
    "def _calibrate_v2(discs, radii, empty_frames, orig, idxs=None, total=None, fill_empty=False):\n",
    "    \"\"\"TODO. Currently same as _calibrate\"\"\"\n",
    "    nonzero = np.array([disc for disc in discs if disc != 0])\n",
    "    del_x = abs(nonzero - orig)[:, 0]\n",
    "    del_y = abs(nonzero - orig)[:, 1]\n",
    "    r = (del_x ** 2 + del_y ** 2) ** 0.5\n",
    "    r = r.mean(axis=0)\n",
    "    \n",
    "    frames = len(discs) if total is None else total\n",
    "    if idxs is None:\n",
    "        idxs = list(range(len(discs)))\n",
    "    \n",
    "    # Estitmate Offset\n",
    "    ref = [1, 0]\n",
    "    thetas_ = [angle_between()]\n",
    "    \n",
    "    thetas = list(np.arange(0, 360, 360/frames))  # Angle with +x axis\n",
    "    \n",
    "    x = lambda r, t: orig + r * np.cos(np.deg2rad(t))\n",
    "    y = lambda r, t: orig + r * np.sin(np.deg2rad(t))\n",
    "    \n",
    "    if not fill_empty:\n",
    "        discs_final = [[x(r, thetas[i]), y(r, thetas[i])] if disc != 0 else 0 for i, disc in zip(idxs, discs)]\n",
    "    else:\n",
    "        discs_final = [[x(r, thetas[i]), y(r, thetas[i])] for i, disc in zip(idxs, discs)]\n",
    "        \n",
    "    r = np.array([rad for rad in radii if rad != 0]).mean()\n",
    "    radii_final = [r for _ in radii]\n",
    "    return discs_final, radii_final\n",
    "    \n",
    "\n",
    "def _calibrate(discs, radii, orig, idxs=None, total=None, fill_empty=False):\n",
    "    nonzero = np.array([disc for disc in discs if disc != 0])\n",
    "    del_x = abs(nonzero - orig)[:, 0]\n",
    "    del_y = abs(nonzero - orig)[:, 1]\n",
    "    r = (del_x ** 2 + del_y ** 2) ** 0.5\n",
    "    r = r.mean(axis=0)\n",
    "    \n",
    "    frames = len(discs) if total is None else total\n",
    "    if idxs is None:\n",
    "        idxs = list(range(len(discs)))\n",
    "\n",
    "    \n",
    "    thetas = list(np.arange(0, 360, 360/frames))  # Angle with +x axis\n",
    "    x = lambda r, t: orig + r * np.cos(np.deg2rad(t))\n",
    "    y = lambda r, t: orig + r * np.sin(np.deg2rad(t))\n",
    "    \n",
    "    if not fill_empty:\n",
    "        discs_final = [[x(r, thetas[i]), y(r, thetas[i])] if disc != 0 else 0 for i, disc in zip(idxs, discs)]\n",
    "    else:\n",
    "        discs_final = [[x(r, thetas[i]), y(r, thetas[i])] for i, disc in zip(idxs, discs)]\n",
    "        \n",
    "    r = np.array([rad for rad in radii if rad != 0]).mean()\n",
    "    radii_final = [r for _ in radii]\n",
    "    return discs_final, radii_final\n",
    "\n",
    "\n",
    "def fivenum(data):\n",
    "    \"\"\"Five-number summary.\"\"\"\n",
    "    return np.percentile(data, [0, 25, 50, 75, 100], interpolation='midpoint')\n",
    "\n",
    "\n",
    "class Predictor(DefaultPredictor):\n",
    "    def __init__(self, cfg, preprocess_fft=True):\n",
    "        cfg.MODEL.RPN.BBOX_REG_LOSS_WEIGHT = 1.0\n",
    "        cfg.MODEL.RPN.BBOX_REG_LOSS_TYPE = \"smooth_l1\"\n",
    "        cfg.MODEL.ROI_BOX_HEAD.BBOX_REG_LOSS_WEIGHT = 1.0\n",
    "        cfg.MODEL.ROI_BOX_HEAD.BBOX_REG_LOSS_TYPE = \"smooth_l1\"\n",
    "\n",
    "        super(Predictor, self).__init__(cfg)\n",
    "        self.preprocess_fft = preprocess_fft\n",
    "\n",
    "    def get_disc(self, tiff_path, visualize=False, warnings=True, return_boxes=False, return_discs_raw=False, idxs=None, total=None, slice_x=None, slice_y=None, calibrate=True, tol=None, fill_empty=False, _no_tqdm=False):\n",
    "        \"\"\"\n",
    "        get_disc(tiff_path, visualize=False, return_boxes=False, _no_tqdm=False)\n",
    "            Predict the center and radii of discs for the given tiff file.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        `tiff_path`: Str, Required\n",
    "                Path to the tiff file.\n",
    "        `visualize`: Boolean, optional\n",
    "                Defaults to False. If set to True, visualizes the predicted discs\n",
    "                on the given tiff file.\n",
    "        `return_boxes`: Boolean, optional\n",
    "                Defaults to False. If set to True, returns the predicted bounding boxes in a list.\n",
    "                Used for testing/debugging.\n",
    "        `_no_tqdm`: Boolean optional\n",
    "                Used internally. When set to True, does not display tqdm progress bar. Defaults to False.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        `discs`: List of shortlisted discs' center coordinates (x, y). If no discs were found in a frame,\n",
    "            0 is put at that index. \n",
    "        `radii`: Estimated radii of the discs. If no discs were found in a frame, 0 is put at that index.\n",
    "        \"\"\"\n",
    "        assert (slice_x is None and slice_y is None) or (slice_x is not None and slice_y is not None), \\\n",
    "            \"Provide either both or None of slice_x and slice_y\"\n",
    "\n",
    "        if isinstance(tiff_path, list):  # If a list of tiff files/numpy arrays is provided\n",
    "            if isinstance(tiff_path[0], np.ndarray):\n",
    "                imgs = tiff_path\n",
    "            else:\n",
    "                imgs = [read_tiff(t)[0] for t in tiff_path]\n",
    "\n",
    "        elif isinstance(tiff_path, np.ndarray):  # If a numpy array is provided\n",
    "            imgs = [tiff_path]\n",
    "\n",
    "        else:  # If a single single/multipage tiff is provided\n",
    "            imgs = read_tiff(tiff_path) \n",
    "\n",
    "        assert idxs is None or len(idxs) == len(imgs), \"Provide enough indices for all of the images.\"\n",
    "\n",
    "        # Preprocessing\n",
    "        if slice_x is not None:  # If the image is to be cropped before processing\n",
    "            imgs = [img[slice_x, slice_y] for img in imgs]\n",
    "\n",
    "        imgs = preprocess(imgs, return_rgb=True, preprocess_fft=self.preprocess_fft)\n",
    "\n",
    "        # Loop for all the frames in the tiff file.\n",
    "        preds = []\n",
    "        imgs_list = tqdm(enumerate(imgs), desc='Running Inference', total=len(imgs)) if not _no_tqdm else enumerate(imgs)\n",
    "        for i, img in imgs_list:\n",
    "            # print(img.shape)  # DEBUG: Should be (128, 128, 3)\n",
    "            pred = self.__call__(original_image=img)['instances'].pred_boxes.tensor.cpu().numpy()\n",
    "            if len(pred) > 2:  # Cannot be more than two discs. Rest must be erroneous.\n",
    "                if warnings:\n",
    "                    print(f'[W] More than 2 detections found in {i}th frame.'\n",
    "                           'Considering only the two most confident detections...'\n",
    "                         )  # Print a warning\n",
    "                pred = pred[:2]  # Take the first 2 (they are sorted by confidence score)\n",
    "            preds.append(pred)\n",
    "\n",
    "        # Get Image Size\n",
    "        imagesize = imgs[0].shape[0]\n",
    "\n",
    "        # Identify the disc\n",
    "        if not return_discs_raw:\n",
    "            discs, radii = _get_discs(preds=preds, imagesize=imagesize, idxs=idxs, total=total, calibrate=calibrate, tol=tol, fill_empty=fill_empty)\n",
    "        else:\n",
    "            discs, radii, discs_raw = _get_discs(preds=preds, imagesize=imagesize, idxs=idxs, total=total, calibrate=calibrate, tol=tol, fill_empty=fill_empty, return_discs_raw=True)\n",
    "\n",
    "        # Visualize Predictions\n",
    "        if visualize and (len(imgs) != 60):\n",
    "            print('The visualization code is only implemented for no. of frames = 60. Showing as much as possible ...')\n",
    "\n",
    "        # Show frames in a 5*12 grid\n",
    "        if visualize:\n",
    "            print('Visualizing predictions...')\n",
    "            if len(imgs) == 1:  # Show the image directly if only one is there\n",
    "                img = imgs[0]  # Grab the frame\n",
    "                d = discs[0]   # Grab the disc\n",
    "                r = radii[0]          # Grab the radius\n",
    "\n",
    "                mask = img.copy()  # Create mask\n",
    "\n",
    "                # Draw the discs on the mask\n",
    "                if d != 0 and r != 0:  # Avoid empty predictions\n",
    "                    mask = cv2.circle(  # First disk\n",
    "                        mask,\n",
    "                        (int(d[0]), int(d[1])),\n",
    "                        int(r),\n",
    "                        (0, 0, 255),\n",
    "                        -1\n",
    "                    )\n",
    "                plt.imshow(cv2.addWeighted(img, 0.6, mask, 0.4, 1))  # Show the frame\n",
    "\n",
    "            else:\n",
    "                fig, axes = plt.subplots(\n",
    "                    nrows=5, ncols=12, sharex=True, sharey=True\n",
    "                )\n",
    "                fig.set_figheight(10)\n",
    "                fig.set_figwidth(24)\n",
    "\n",
    "                pbar = tqdm(total=len(imgs), desc='Drawing Circles')  # Progress bar\n",
    "                for i in range(5):\n",
    "                    for j in range(12):\n",
    "                        ax = axes[i, j]\n",
    "                        try:\n",
    "                            img = imgs[i*12 + j]  # Grab the frame\n",
    "                            d = discs[i*12 + j]   # Grab the disc\n",
    "                            r = radii[i]          # Grab the radius\n",
    "\n",
    "                        except IndexError:  # imgs has < 60 frames:\n",
    "                            continue  # Skip\n",
    "\n",
    "                        mask = img.copy()  # Empty mask\n",
    "\n",
    "                        # Draw the discs on the mask\n",
    "                        if d != 0 and r != 0:  # Avoid empty predictions\n",
    "                            mask = cv2.circle(  # First disk\n",
    "                                mask,\n",
    "                                (int(d[0]), int(d[1])),\n",
    "                                int(r),\n",
    "                                (0, 0, 255),\n",
    "                                -1\n",
    "                            )\n",
    "\n",
    "                        # Overlay mask on top of the frame and show\n",
    "                        ax.imshow(cv2.addWeighted(img, 0.6, mask, 0.4, 1))  # Show the frame\n",
    "                        pbar.update(1)  # Update Progress Bar\n",
    "                pbar.close()  # Stop the progress bar\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        ret = [discs, radii]\n",
    "\n",
    "        # Return predictions if asked\n",
    "        if return_boxes:\n",
    "            ret.append(preds)\n",
    "        if return_discs_raw:\n",
    "            ret.append(discs_raw)\n",
    "        return ret\n",
    "\n",
    "    def get_k(self, tiff_path, metadata, warnings=True):\n",
    "        \"\"\"\n",
    "        get_k(tiff_path, metadata)\n",
    "            Get *Real* (not fourier domain) K0X and K0Y values for an input tiff file.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        `tiff_path`: String, required\n",
    "                Path to the tiff file.\n",
    "        `metadata`: Dictionary, required\n",
    "                It should have these keys: PIXELSIZE, RI, MAGNIFICATION, IMAGESIZE,\n",
    "                ILLUMINATION_OFFCENTER_X, ILLUMINATION_OFFCENTER_Y with their values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        `k0x`, `k0y`: *Real-domain* K0X and K0Y values in a Numpy array.\n",
    "        \"\"\"\n",
    "        PIXELSIZE = int(metadata['PIXELSIZE'])\n",
    "        IMAGESIZE = int(metadata['IMAGESIZE'])\n",
    "        RI = float(metadata['RI'])\n",
    "        MAGNIFICATION = int(metadata['MAGNIFICATION'])\n",
    "        ILLUMINATION_OFFCENTER_X = float(metadata['ILLUMINATION_OFFCENTER_X'])\n",
    "        ILLUMINATION_OFFCENTER_Y = float(metadata['ILLUMINATION_OFFCENTER_Y'])\n",
    "\n",
    "        NYQUIST_FREQ = 2 * np.pi / (2 * PIXELSIZE / (RI * MAGNIFICATION))  # formula\n",
    "        discs, _ = self.get_disc(tiff_path, warnings=warnings)\n",
    "        delta_x = np.array([disc if disc!=0 else [0, 0] for disc in discs])[:, 0]\n",
    "        delta_y = np.array([disc if disc!=0 else [0, 0] for disc in discs])[:, 1]\n",
    "\n",
    "        k0x = (np.array(delta_x) - ILLUMINATION_OFFCENTER_X) * NYQUIST_FREQ / (IMAGESIZE/2)\n",
    "        k0y = (np.array(delta_y) - ILLUMINATION_OFFCENTER_Y) * NYQUIST_FREQ / (IMAGESIZE/2)\n",
    "        return k0x, k0y\n",
    "\n",
    "    def eval_disc_MAE(self, holdout_df, calibrate=False, fill_empty=True, print_fivenum=False, warnings=True):\n",
    "        \"\"\"\n",
    "        eval_disc_MAE(holdout_df)\n",
    "            Calculates MAE (Mean Absolute Error) for delta_x, delta_y and r.\n",
    "\n",
    "       Parameters\n",
    "        ----------\n",
    "        `holdout_df`: Pandas DataFrame, required\n",
    "                Part of the labels dataframe you want to evaluate the model's performance on.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        `mae_delta_x`, `mae_delta_y`, `mae_r`: MAE for delta_x, delta_y and r respectively.\n",
    "        \"\"\"\n",
    "        assert isinstance(holdout_df, pd.DataFrame), 'Please pass a pandas DataFrame'\n",
    "\n",
    "        # Get a list of all the files\n",
    "        files = holdout_df.file\n",
    "        mae_delta_x = {\n",
    "            'px': [],  # in pixels\n",
    "            'um': [],  # in micrometers\n",
    "        }\n",
    "        mae_delta_y = {\n",
    "            'px': [],  # in pixels\n",
    "            'um': [],  # in micrometers\n",
    "        }\n",
    "        mae_r = {\n",
    "            'px': [],  # in pixels\n",
    "            'um': [],  # in micrometers\n",
    "        }\n",
    "        mae_delta = {\n",
    "            'px': [],  # in pixels\n",
    "            'um': [],  # in micrometers\n",
    "        }\n",
    "\n",
    "        # Calculate MAE in a loop\n",
    "        for file in tqdm(files, desc='Files completed', total=len(files)):\n",
    "            # Get predictions\n",
    "            discs, r = self.get_disc(\n",
    "                tiff_path=file,\n",
    "                visualize=False,\n",
    "                _no_tqdm=True, \n",
    "                calibrate=calibrate,\n",
    "                fill_empty=fill_empty,\n",
    "                warnings=warnings\n",
    "            )\n",
    "            # Get the labels' row\n",
    "            row = holdout_df[holdout_df.file==file]\n",
    "\n",
    "            orig = int(row.IMAGESIZE) // 2 - 1\n",
    "\n",
    "            delta_x = np.array([disc if disc!=0 else [orig, orig] for disc in discs])[:, 0] - orig\n",
    "            delta_y = np.array([disc if disc!=0 else [orig, orig] for disc in discs])[:, 1] - orig\n",
    "\n",
    "            delta = np.sqrt(delta_x ** 2 + delta_y ** 2)\n",
    "\n",
    "            #Ignore zero values (corresponding to empty frames)\n",
    "#             nonzero = (np.array(delta_x) != 0).squeeze() & (np.array(delta_y) != 0).squeeze() & (np.array(r) != 0).squeeze()\n",
    "            nonzero = np.invert((np.array(delta_x) == 0).squeeze() & (np.array(delta_y) == 0).squeeze()).squeeze()\n",
    "            # Get ground truth\n",
    "            delta_x_true, delta_y_true, r_true = get_label(file, holdout_df, return_delta=True)\n",
    "\n",
    "            delta_true = np.sqrt(delta_x_true ** 2 + delta_y_true ** 2)\n",
    "\n",
    "\n",
    "            # Calculate conversion factor\n",
    "            PIXELSIZE = int(row.PIXELSIZE)\n",
    "            IMAGESIZE = int(row.IMAGESIZE)\n",
    "            RI = float(row.RI)\n",
    "            MAGNIFICATION = int(row.MAGNIFICATION)\n",
    "            NYQUIST_FREQ = 2 * np.pi / (2 * PIXELSIZE / (RI * MAGNIFICATION)) # formula\n",
    "            conv_factor = 2 * NYQUIST_FREQ / IMAGESIZE\n",
    "\n",
    "            # MAE calculation (micrometers)\n",
    "            mae_delta_x['um'].append(\n",
    "                conv_factor * abs(((np.array(delta_x).squeeze()[nonzero]) - (delta_x_true[nonzero]))).mean()\n",
    "            )\n",
    "            mae_delta_y['um'].append(\n",
    "                conv_factor * abs(((np.array(delta_y).squeeze()[nonzero]) - (delta_y_true[nonzero]))).mean()\n",
    "            )\n",
    "            mae_delta['um'].append(\n",
    "                conv_factor * abs(((np.array(delta).squeeze()[nonzero]) - (delta_true[nonzero]))).mean()\n",
    "            )\n",
    "            mae_r['um'].append(\n",
    "                conv_factor * abs(np.array(r).squeeze()[nonzero] - r_true).mean()\n",
    "            )\n",
    "\n",
    "            # MAE calculation (pixels)\n",
    "            mae_delta_x['px'].append(\n",
    "                abs(((np.array(delta_x).squeeze()[nonzero]) - (delta_x_true[nonzero]))).mean()\n",
    "            )\n",
    "            mae_delta_y['px'].append(\n",
    "                abs(((np.array(delta_y).squeeze()[nonzero]) - (delta_y_true[nonzero]))).mean()\n",
    "            )\n",
    "            mae_delta['px'].append(\n",
    "                abs(((np.array(delta).squeeze()[nonzero]) - (delta_true[nonzero]))).mean()\n",
    "            )\n",
    "            mae_r['px'].append(\n",
    "                abs(np.array(r).squeeze()[nonzero] - r_true).mean()\n",
    "            )\n",
    "\n",
    "\n",
    "            ##############\n",
    "#             # MAE calculation (micrometers)\n",
    "#             mae_delta_x['um'].append(\n",
    "#                 conv_factor * abs((abs(np.array(delta_x).squeeze()[nonzero]) - abs(delta_x_true[nonzero]))).mean()\n",
    "#             )\n",
    "#             mae_delta_y['um'].append(\n",
    "#                 conv_factor * abs((abs(np.array(delta_y).squeeze()[nonzero]) - abs(delta_y_true[nonzero]))).mean()\n",
    "#             )\n",
    "#             mae_r['um'].append(\n",
    "#                 conv_factor * abs(np.array(r).squeeze()[nonzero] - r_true).mean()\n",
    "#             )\n",
    "\n",
    "#             # MAE calculation (pixels)\n",
    "#             mae_delta_x['px'].append(\n",
    "#                 abs((abs(np.array(delta_x).squeeze()[nonzero]) - abs(delta_x_true[nonzero]))).mean()\n",
    "#             )\n",
    "#             mae_delta_y['px'].append(\n",
    "#                 abs((abs(np.array(delta_y).squeeze()[nonzero]) - abs(delta_y_true[nonzero]))).mean()\n",
    "#             )\n",
    "#             mae_r['px'].append(\n",
    "#                 abs(np.array(r).squeeze()[nonzero] - r_true).mean()\n",
    "#             )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(f'Mean absolute error in delta_x: {np.array(mae_delta_x[\"um\"]).mean()} micrometers'\n",
    "              f'\\t or \\t {np.array(mae_delta_x[\"px\"]).mean()} pixels')\n",
    "        print(f'Mean absolute error in delta_y: {np.array(mae_delta_y[\"um\"]).mean()} micrometers'\n",
    "              f'\\t or \\t {np.array(mae_delta_y[\"px\"]).mean()} pixels')\n",
    "        print(f'Mean absolute error in delta: {np.array(mae_delta[\"um\"]).mean()} micrometers'\n",
    "              f'\\t or \\t {np.array(mae_delta[\"px\"]).mean()} pixels')\n",
    "        print(f'Mean absolute error in r: {np.array(mae_r[\"um\"]).mean()} micrometers'\n",
    "              f'\\t or \\t {np.array(mae_r[\"px\"]).mean()} pixels')\n",
    "\n",
    "        if print_fivenum:\n",
    "            print(f'fivenum of error in delta_x: \\n {fivenum(np.array(mae_delta_x[\"um\"]))} micrometers'\n",
    "                  f'\\n\\t or \\t {fivenum(np.array(mae_delta_x[\"px\"]))} pixels')\n",
    "            print(f'fivenum of error in delta_y: {fivenum(np.array(mae_delta_y[\"um\"]))} micrometers'\n",
    "                  f'\\t or \\t {fivenum(np.array(mae_delta_y[\"px\"]))} pixels')\n",
    "            print(f'fivenum of error in delta: {fivenum(np.array(mae_delta[\"um\"]))} micrometers'\n",
    "                  f'\\t or \\t {fivenum(np.array(mae_delta[\"px\"]))} pixels')\n",
    "            print(f'fivenum of error in r: {fivenum(np.array(mae_r[\"um\"]))} micrometers'\n",
    "                  f'\\t or \\t {fivenum(np.array(mae_r[\"px\"]))} pixels')\n",
    "\n",
    "        return mae_delta_x, mae_delta_y, mae_delta, mae_r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
